{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge craiglist data with synthetic census data\n",
    "\n",
    "Steps: \n",
    "\n",
    "1. Get craigslist data \n",
    " - Query from remote database in batches based on FIPS\n",
    " - Joing to census via FIPS code\n",
    "2. Get census data \n",
    " - Aggregate to BG\n",
    "3. Merge together\n",
    "\n",
    "Can process in batches, one state at a time, or get data by region.\n",
    "\n",
    "TODO: \n",
    " - The census data for DC are missing. The files are there but they contain no data.\n",
    " - If need to look at education or other person data, aggregate person data to household and then block group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import paramiko\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Craigslist data table columns\n",
    "\n",
    "pid          | character varying(25)  |\n",
    " date         | date                   | \n",
    " region       | character varying(50)  | \n",
    " neighborhood | character varying(200) | \n",
    " rent         | double precision       | \n",
    " bedrooms     | double precision       | \n",
    " sqft         | double precision       | \n",
    " rent_sqft    | double precision       | \n",
    " longitude    | double precision       | \n",
    " latitude     | double precision       | \n",
    " county       | character varying(20)  | \n",
    " fips_block   | character varying(20)  | \n",
    " state        | character varying(20)  | \n",
    " bathrooms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FIPS code format**\n",
    "\n",
    " 53-----033---001701--1--015\n",
    "\n",
    "[state][county][tract][bg][block]\n",
    "\n",
    "Note: for DC, county='001'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic census data - variables\n",
    "\n",
    "**Household data**: household_id,serialno,persons,cars,income,race_of_head,age_of_head,workers,state,county,tract,block group,children,tenure,recent_mover\n",
    "\n",
    "**Person data**: person_id,member_id,age,relate,edu,sex,hours,earning,race_id,household_id,student,work_at_home,worker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure connection parameters\n",
    "\n",
    "Make sure you have two files saved in the same directory, postgres_settings.json and ssh_settings.json. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_DIR=os.path.join('..','data') \n",
    "\"\"\"Path to local data directory\"\"\"\n",
    "\n",
    "#read postgres connection parameters\n",
    "with open('postgres_settings.json') as settings_file:    \n",
    "    settings = json.load(settings_file)\n",
    "\n",
    "DBNAME = settings['dbname']\n",
    "USER = settings['user']\n",
    "HOST = settings['host']\n",
    "PASSWORD = settings['password']\n",
    "\n",
    "conn_str = \"dbname = {0} user = {1} host = {2} password = {3}\".format(DBNAME, USER, HOST, PASSWORD)\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(conn_str)\n",
    "    cur = conn.cursor()\n",
    "except:\n",
    "    print (\"Cannot connection. Check settings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: add putty connection too. \n",
    "#read SSH connection parameters\n",
    "with open('ssh_settings.json') as settings_file:    \n",
    "    settings = json.load(settings_file)\n",
    "\n",
    "HOSTNAME = settings['hostname']\n",
    "USERNAME = settings['username']\n",
    "PASSWORD = settings['password']\n",
    "LOCAL_KEY_DIR = settings['local_key_dir']\n",
    "\n",
    "CENSUS_DIR = 'synthetic_population'\n",
    "\"\"\"Remote directory with census data\"\"\"\n",
    "\n",
    "RESULTS_DIR = 'craigslist_census'\n",
    "\"\"\"Remote directory for results\"\"\"\n",
    "\n",
    "# estbalish SSH connection\n",
    "ssh = paramiko.SSHClient() \n",
    "ssh.load_host_keys(LOCAL_KEY_DIR)\n",
    "ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "ssh.connect(HOSTNAME,username=USERNAME, password=PASSWORD)\n",
    "sftp = ssh.open_sftp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local data files\n",
    "\n",
    "Local files with with block-level data from urbansim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BLOCK_DIR = os.path.join('..','data','urbansim')\n",
    "BLOCK_ZFILE = 'ba_block_variables.csv.zip'\n",
    "BLOCK_FILE = 'ba_block_variables.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create FIPS look-up tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>MPO_ID</th>\n",
       "      <th>MPONAME</th>\n",
       "      <th>STATE</th>\n",
       "      <th>STFIPS</th>\n",
       "      <th>STATEFP</th>\n",
       "      <th>COUNTYFP</th>\n",
       "      <th>COUNTYNS</th>\n",
       "      <th>GEOID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>...</th>\n",
       "      <th>CBSAFP</th>\n",
       "      <th>METDIVFP</th>\n",
       "      <th>FUNCSTAT</th>\n",
       "      <th>ALAND</th>\n",
       "      <th>AWATER</th>\n",
       "      <th>INTPTLAT</th>\n",
       "      <th>INTPTLON</th>\n",
       "      <th>PERIMETER</th>\n",
       "      <th>area_sqmi</th>\n",
       "      <th>st_co_fips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1826900.0</td>\n",
       "      <td>47198201</td>\n",
       "      <td>Johnson City Metropolitan Transportation Plann...</td>\n",
       "      <td>TN</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>163</td>\n",
       "      <td>1639793</td>\n",
       "      <td>47163</td>\n",
       "      <td>Sullivan</td>\n",
       "      <td>...</td>\n",
       "      <td>28700.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>1.070725e+09</td>\n",
       "      <td>4.220920e+07</td>\n",
       "      <td>36.510213</td>\n",
       "      <td>-82.299396</td>\n",
       "      <td>71837.801334</td>\n",
       "      <td>0.756540</td>\n",
       "      <td>47163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1541707.0</td>\n",
       "      <td>29201300</td>\n",
       "      <td>Southeast Metropolitan Planning Organization (...</td>\n",
       "      <td>MO</td>\n",
       "      <td>29</td>\n",
       "      <td>17</td>\n",
       "      <td>003</td>\n",
       "      <td>424203</td>\n",
       "      <td>17003</td>\n",
       "      <td>Alexander</td>\n",
       "      <td>...</td>\n",
       "      <td>16020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>6.099969e+08</td>\n",
       "      <td>4.423719e+07</td>\n",
       "      <td>37.183657</td>\n",
       "      <td>-89.349516</td>\n",
       "      <td>6972.897419</td>\n",
       "      <td>0.591829</td>\n",
       "      <td>29003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2101128.0</td>\n",
       "      <td>51197401</td>\n",
       "      <td>Richmond Area MPO</td>\n",
       "      <td>VA</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>670</td>\n",
       "      <td>1498428</td>\n",
       "      <td>51670</td>\n",
       "      <td>Hopewell</td>\n",
       "      <td>...</td>\n",
       "      <td>40060.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>2.665508e+07</td>\n",
       "      <td>1.324078e+06</td>\n",
       "      <td>37.291010</td>\n",
       "      <td>-77.298944</td>\n",
       "      <td>6041.591069</td>\n",
       "      <td>0.257294</td>\n",
       "      <td>51670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220693.0</td>\n",
       "      <td>15201300</td>\n",
       "      <td>Maui MPO</td>\n",
       "      <td>HI</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>009</td>\n",
       "      <td>365283</td>\n",
       "      <td>15009</td>\n",
       "      <td>Maui</td>\n",
       "      <td>...</td>\n",
       "      <td>27980.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.286608e+09</td>\n",
       "      <td>-1.091674e+09</td>\n",
       "      <td>20.855931</td>\n",
       "      <td>-156.601550</td>\n",
       "      <td>299148.486465</td>\n",
       "      <td>728.079214</td>\n",
       "      <td>15009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220707.0</td>\n",
       "      <td>15197500</td>\n",
       "      <td>Oahu MPO</td>\n",
       "      <td>HI</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>003</td>\n",
       "      <td>365281</td>\n",
       "      <td>15003</td>\n",
       "      <td>Honolulu</td>\n",
       "      <td>...</td>\n",
       "      <td>46520.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>1.555505e+09</td>\n",
       "      <td>-2.400273e+08</td>\n",
       "      <td>21.461365</td>\n",
       "      <td>-158.201974</td>\n",
       "      <td>329335.691836</td>\n",
       "      <td>610.910815</td>\n",
       "      <td>15003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID    MPO_ID                                            MPONAME  \\\n",
       "0  1826900.0  47198201  Johnson City Metropolitan Transportation Plann...   \n",
       "1  1541707.0  29201300  Southeast Metropolitan Planning Organization (...   \n",
       "2  2101128.0  51197401                                  Richmond Area MPO   \n",
       "3   220693.0  15201300                                           Maui MPO   \n",
       "4   220707.0  15197500                                           Oahu MPO   \n",
       "\n",
       "  STATE STFIPS  STATEFP COUNTYFP  COUNTYNS  GEOID       NAME     ...      \\\n",
       "0    TN     47       47      163   1639793  47163   Sullivan     ...       \n",
       "1    MO     29       17      003    424203  17003  Alexander     ...       \n",
       "2    VA     51       51      670   1498428  51670   Hopewell     ...       \n",
       "3    HI     15       15      009    365283  15009       Maui     ...       \n",
       "4    HI     15       15      003    365281  15003   Honolulu     ...       \n",
       "\n",
       "    CBSAFP  METDIVFP FUNCSTAT         ALAND        AWATER   INTPTLAT  \\\n",
       "0  28700.0       NaN        A  1.070725e+09  4.220920e+07  36.510213   \n",
       "1  16020.0       NaN        A  6.099969e+08  4.423719e+07  37.183657   \n",
       "2  40060.0       NaN        F  2.665508e+07  1.324078e+06  37.291010   \n",
       "3  27980.0       NaN        A -1.286608e+09 -1.091674e+09  20.855931   \n",
       "4  46520.0       NaN        A  1.555505e+09 -2.400273e+08  21.461365   \n",
       "\n",
       "     INTPTLON      PERIMETER   area_sqmi  st_co_fips  \n",
       "0  -82.299396   71837.801334    0.756540       47163  \n",
       "1  -89.349516    6972.897419    0.591829       29003  \n",
       "2  -77.298944    6041.591069    0.257294       51670  \n",
       "3 -156.601550  299148.486465  728.079214       15009  \n",
       "4 -158.201974  329335.691836  610.910815       15003  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make dictionary of states and fips codes. \n",
    "fips_state = pd.read_csv(os.path.join(DATA_DIR,'state_fips_codes.csv'),dtype=str)\n",
    "fips2state=dict(zip(fips_state['FIPS'],fips_state['USPS']))\n",
    "state2fips=dict(zip(fips_state['USPS'],fips_state['FIPS']))\n",
    "\n",
    "# Make lookup for county to MPO code \n",
    "mpo_counties = pd.read_csv(os.path.join(DATA_DIR,'us_2015_mpo_regions_counties_v1.csv'), encoding='latin1', dtype={'MPO_ID':str,'COUNTYFP':str,'STFIPS':str})\n",
    "mpo_counties['COUNTYFP'] = mpo_counties['COUNTYFP'].str.zfill(2)  \n",
    "mpo_counties['st_co_fips'] = mpo_counties['STFIPS']+mpo_counties['COUNTYFP']  # we will want to join on 2-char state + 3-char county fips\n",
    "county2mpo=dict(zip(mpo_counties['st_co_fips'],mpo_counties['MPO_ID']))  # do we want MPO_ID or do we want GEOID? \n",
    "mpo_counties.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_query(q):\n",
    "    \"\"\" Get results given SQL query\"\"\"\n",
    "    cur.execute(q)\n",
    "    return(cur.fetchall())\n",
    "\n",
    "def get_craiglist(filters, split_fips=True):\n",
    "    \"\"\"Get craiglist data from database.\n",
    "    Args: \n",
    "        filters (list): list of strings containing filter criteria. Format as individual SQL WHERE statements. E.g., [\"region='sandiego'\",\"rent>100\"]\n",
    "        split_fips (bool): if True, split fips code into block and fips12 (useful if merging wtih blockgroup)\n",
    "    Returns: \n",
    "        DataFrame: listings data. \n",
    "    \"\"\"\n",
    "    #q=\"SELECT pid,date,rent,bedrooms,bathrooms,sqft,rent_sqft,fips_block,state,region,longitude,latitude FROM rental_listings WHERE state='{}';\".format(state)\n",
    "    filters_str = ' AND '.join([x for x in filters])\n",
    "    q=\"SELECT pid,date,rent,bedrooms,bathrooms,sqft,rent_sqft,fips_block,state,region,longitude,latitude FROM rental_listings WHERE {};\".format(filters_str)\n",
    "    results=run_query(q)\n",
    "    df=pd.DataFrame(results,columns=['listing_id', 'date','rent','bedrooms','bathrooms','sqft','rent_sqft','fips_block','state','region','lng','lat'] )  # put it all into a dataframe\n",
    "    if split_fips==True:\n",
    "        # split FIPS into different columns - split off the last 3 chars\n",
    "        df['block']=df.fips_block.str[-4:]\n",
    "        df['fips12']=df.fips_block.str[:-3]\n",
    "    return(df)\n",
    "\n",
    "def read_census_file(fname):\n",
    "    \"\"\"Read census csv file via SFTP and return as dataframe.\"\"\"\n",
    "    with sftp.open(os.path.join(CENSUS_DIR,fname)) as f:\n",
    "        df = pd.read_csv(f, delimiter=',',dtype={'age_of_head':float, 'block group':str, 'cars':float, 'children':float, 'county':str,\n",
    "           'household_id':str, 'income':float, 'persons':float, 'race_of_head':str, 'recent_mover':str,\n",
    "           'serialno':str, 'state':str, 'tenure':str, 'tract':str, 'workers':float})\n",
    "    return df\n",
    "\n",
    "def write_results_file(data,fname):\n",
    "    \"\"\"Write merged data to csv file via SFTP.\"\"\"\n",
    "    with sftp.open(os.path.join(RESULTS_DIR,fname),'w') as f:\n",
    "        data.to_csv(f,index=True)\n",
    "    return\n",
    "\n",
    "def get_census_by_state(state, table='households'): \n",
    "    \"\"\"Return all census data for state given two-char abbreviation. Can be 'households' or 'persons' data. \"\"\" \n",
    "    filelist=sftp.listdir(CENSUS_DIR)\n",
    "    if table=='households':\n",
    "        files = [f for f in filelist if f[:5]=='hh_{}'.format(state)]\n",
    "    elif table=='persons':\n",
    "        files = [f for f in filelist if f[:4]=='p_{}'.format(state)]\n",
    "    #files = files[:3]  # uncomment this line for testing.\n",
    "    new_df = pd.DataFrame()\n",
    "    for f in files:\n",
    "        df = read_census_file(f)\n",
    "        new_df = pd.concat([new_df,df])\n",
    "    return(new_df)\n",
    "\n",
    "def strip_zeros(s):\n",
    "    \"\"\"Remove '.0 from end of string\"\"\"\n",
    "    if s.endswith('.0'):\n",
    "        return(s[:-2])\n",
    "    else:\n",
    "        return(s)\n",
    "\n",
    "def format_hh_data(df):\n",
    "    \"\"\"Fix formatting for hhs census data. Replace '' strings with zero. Format other strings.\"\"\"\n",
    "\n",
    "    df['county'] = df['county'].str.zfill(2)  # make county 3-char string.\n",
    "    \n",
    "    for col in ['children','workers']:\n",
    "        df[col] = df[col].replace('','0')\n",
    "\n",
    "    for col in ['race_of_head','recent_mover','tenure']:\n",
    "        df[col] = df[col].astype(str)\n",
    "        df[col] = df[col].map(strip_zeros)  # make sure strings are formatted. \n",
    "    return(df)\n",
    "\n",
    "def aggregate_census(df, groupby_cols=['county','tract','block group'],cols_to_sum=['cars','children','persons','workers'], cols_to_median=['age_of_head','income'],categ_cols=['race_of_head','recent_mover','tenure'],id_col='serialno',table='hhs'):\n",
    "    \"\"\"Aggregate census table to block group. Made this for hh data, may need to revised for persons data.\n",
    "    Args: \n",
    "        groupby_cols (list): names of columns to group by (default=['county','tract','block group'])\n",
    "        cols_to_sum (list): names of columns for which to compute totals. \n",
    "        cols_to_median (list): names of columns for which to compute medians\n",
    "        categ_cols (list): names of categorical columns\n",
    "        id_col (str): name of column that serves as the id column, to use in counting rows. \n",
    "        table (str): 'hhs' (default) or 'per'\n",
    "    Returns: \n",
    "        DataFrame: aggregated data. \n",
    "        \"\"\"\n",
    "    # For some columns we'll want to find the sum or average/median. These will need only a simple groupby \n",
    "    sums = df.groupby(by=groupby_cols).sum()[cols_to_sum]\n",
    "    sums.columns = [x+'_tot' for x in cols_to_sum]\n",
    "    \n",
    "    medians = df.groupby(by=groupby_cols).median()[cols_to_median]\n",
    "    medians.columns = [x+'_med' for x in cols_to_median]\n",
    "    \n",
    "    counts = pd.DataFrame(df.groupby(by=groupby_cols).count()[id_col])\n",
    "    counts.columns=[table+'_tot']\n",
    "\n",
    "    # Categorical columns will need pivot tables. \n",
    "    categoricals = pd.DataFrame(index=counts.index)\n",
    "    for col in categ_cols:\n",
    "        pivoted=df.pivot_table(index = groupby_cols, columns = col, aggfunc='count')[id_col]\n",
    "        pivoted.columns = [col+'_'+x for x in pivoted.columns]\n",
    "        pivoted.columns = pivoted.columns.map(strip_zeros)\n",
    "        # merge back together\n",
    "        categoricals = pd.merge(categoricals, pivoted, left_index=True, right_index=True)\n",
    "\n",
    "    # put all back together in one table\n",
    "    merged = pd.merge(sums, medians, left_index=True, right_index=True)\n",
    "    merged = pd.merge(merged, counts, left_index=True, right_index=True)\n",
    "    merged = pd.merge(merged, categoricals, left_index=True, right_index=True)\n",
    "\n",
    "    # check lengths of dataframes to detect any problems in grouping or merging\n",
    "    lengths = [len(sums),len(medians),len(counts),len(categoricals),len(merged)]\n",
    "    if len(set(lengths))>1:\n",
    "        print('Warning: Aggregated tables have different lengths.',lengths,'for sums, medians, counts, categoricals, and merged.')\n",
    "    \n",
    "    return(merged)\n",
    "\n",
    "def match_mpo(s, mpo_dict=county2mpo):\n",
    "    \"\"\"Match a 5-char state-county FIPS code to an MPO code\n",
    "    Args: \n",
    "        s (str): 5-char state-county string\n",
    "        mpo_dict (dict): county2mpo dictionary\n",
    "    Returns: \n",
    "        str: MPO code\n",
    "    \"\"\"\n",
    "    try: \n",
    "        return mpo_dict[s]\n",
    "    except KeyError: # in this case, the county is not in an MPO\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_all(state, filters=None):\n",
    "    \"\"\"Get craigslist data and merge with census data, by state, and save.  with additional filters if needed. \n",
    "    Args: \n",
    "        state (str): 2-char state abbreviation\n",
    "        filters (list): additional filters. Do not need to include state in filter list\n",
    "    \"\"\"\n",
    "    \n",
    "    # load and prepare craiglist data\n",
    "    \n",
    "    # If filters are provided, use them to filter data\n",
    "    if filters:\n",
    "        filters.append(\"state='{}'\".format(state))\n",
    "        print(filters)\n",
    "        df_cl=get_craiglist(filters)\n",
    "    # If no filters provided, get all data for the specified state. \n",
    "    else:\n",
    "        df_cl=get_craiglist([\"state='{}'\".format(state)])\n",
    "    \n",
    "    df_cl['st_co_fps'] = df_cl.fips_block.map(lambda x: x[:5])\n",
    "    df_cl['mpo_id'] = df_cl.st_co_fps.map(match_mpo)\n",
    "\n",
    "    # load and prepare census data for households\n",
    "    hhs = get_census_by_state(state, table='households')\n",
    "    hhs = format_hh_data(hhs)\n",
    "    hhs_bg = aggregate_census(hhs)\n",
    "    hhs_bg=hhs_bg.reset_index()\n",
    "    hhs_bg['fips12']=state2fips[state]+hhs_bg['county']+hhs_bg['tract']+hhs_bg['block group'] # create 12-digit FIPS code for merging. \n",
    "\n",
    "    # merge with craigslist data. \n",
    "    merged = pd.merge(df_cl, hhs_bg, on='fips12',how='left')\n",
    "    merged = merged.set_index('listing_id')\n",
    "\n",
    "    #TODO: add persons data here, if needed. \n",
    "\n",
    "    # Keep only columns we'll need.\n",
    "    cols_to_keep=['date','rent','bedrooms','bathrooms','sqft','rent_sqft','fips_block','state','region','mpo_id','lng','lat','cars_tot','children_tot','persons_tot','workers_tot','age_of_head_med','income_med','hhs_tot','race_of_head_1','race_of_head_2','race_of_head_3','race_of_head_4','race_of_head_5','race_of_head_6','race_of_head_7','race_of_head_8','race_of_head_9','recent_mover_0','recent_mover_1','tenure_1','tenure_2']\n",
    "    \n",
    "    # This is a bit of a hack in case some columns are missing in some states. \n",
    "    for col in cols_to_keep: \n",
    "        if col not in merged.columns:\n",
    "            merged[col] = np.nan\n",
    "\n",
    "    # save file either locally or remotely. \n",
    "    print('Saving data for {s}: {m} rows'.format(s=state,m=len(merged)))\n",
    "    outfile = 'cl_census_{}.csv'.format(state)\n",
    "    #merged[cols_to_keep].to_csv(os.path.join(DATA_DIR,outfile), index=True)  # uncomment to save locally\n",
    "\n",
    "    #write_results_file(merged[cols_to_keep], outfile)  # uncomment to save remotely. \n",
    "    return merged[cols_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data for a single region\n",
    "\n",
    "Use this to get data for a single region, for use in our preliminary analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"region = 'sfbay'\", 'rent>0', \"state='CA'\"]\n",
      "Saving data for CA: 125539 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>rent</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft</th>\n",
       "      <th>rent_sqft</th>\n",
       "      <th>fips_block</th>\n",
       "      <th>state</th>\n",
       "      <th>region</th>\n",
       "      <th>mpo_id</th>\n",
       "      <th>...</th>\n",
       "      <th>race_of_head_4</th>\n",
       "      <th>race_of_head_5</th>\n",
       "      <th>race_of_head_6</th>\n",
       "      <th>race_of_head_7</th>\n",
       "      <th>race_of_head_8</th>\n",
       "      <th>race_of_head_9</th>\n",
       "      <th>recent_mover_0</th>\n",
       "      <th>recent_mover_1</th>\n",
       "      <th>tenure_1</th>\n",
       "      <th>tenure_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listing_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5925013098</th>\n",
       "      <td>2016-12-18</td>\n",
       "      <td>2495.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>398.0</td>\n",
       "      <td>6.268844</td>\n",
       "      <td>060750162001001</td>\n",
       "      <td>CA</td>\n",
       "      <td>sfbay</td>\n",
       "      <td>06197001</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5925007228</th>\n",
       "      <td>2016-12-18</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1357.0</td>\n",
       "      <td>2.431835</td>\n",
       "      <td>060133342005000</td>\n",
       "      <td>CA</td>\n",
       "      <td>sfbay</td>\n",
       "      <td>06197001</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>357.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5925014745</th>\n",
       "      <td>2016-12-18</td>\n",
       "      <td>1657.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>915.0</td>\n",
       "      <td>1.810929</td>\n",
       "      <td>060855091022006</td>\n",
       "      <td>CA</td>\n",
       "      <td>sfbay</td>\n",
       "      <td>06197001</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>782.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>707.0</td>\n",
       "      <td>539.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1074.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5921274233</th>\n",
       "      <td>2016-12-18</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>060871006002003</td>\n",
       "      <td>CA</td>\n",
       "      <td>sfbay</td>\n",
       "      <td>06197502</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>337.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5925012514</th>\n",
       "      <td>2016-12-18</td>\n",
       "      <td>2195.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>443.0</td>\n",
       "      <td>4.954853</td>\n",
       "      <td>060750125011002</td>\n",
       "      <td>CA</td>\n",
       "      <td>sfbay</td>\n",
       "      <td>06197001</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>473.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1190.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date    rent  bedrooms  bathrooms    sqft  rent_sqft  \\\n",
       "listing_id                                                               \n",
       "5925013098  2016-12-18  2495.0       0.0        NaN   398.0   6.268844   \n",
       "5925007228  2016-12-18  3300.0       2.0        NaN  1357.0   2.431835   \n",
       "5925014745  2016-12-18  1657.0       2.0        NaN   915.0   1.810929   \n",
       "5921274233  2016-12-18  1700.0       1.0        NaN   500.0   3.400000   \n",
       "5925012514  2016-12-18  2195.0       1.0        NaN   443.0   4.954853   \n",
       "\n",
       "                 fips_block state region    mpo_id    ...     race_of_head_4  \\\n",
       "listing_id                                            ...                      \n",
       "5925013098  060750162001001    CA  sfbay  06197001    ...                1.0   \n",
       "5925007228  060133342005000    CA  sfbay  06197001    ...                NaN   \n",
       "5925014745  060855091022006    CA  sfbay  06197001    ...                NaN   \n",
       "5921274233  060871006002003    CA  sfbay  06197502    ...                NaN   \n",
       "5925012514  060750125011002    CA  sfbay  06197001    ...                NaN   \n",
       "\n",
       "            race_of_head_5  race_of_head_6  race_of_head_7  race_of_head_8  \\\n",
       "listing_id                                                                   \n",
       "5925013098             NaN            42.0             2.0            14.0   \n",
       "5925007228             NaN             NaN             NaN             NaN   \n",
       "5925014745             2.0           782.0             NaN             8.0   \n",
       "5921274233             NaN            14.0             NaN             NaN   \n",
       "5925012514            10.0           473.0             8.0            69.0   \n",
       "\n",
       "            race_of_head_9  recent_mover_0  recent_mover_1  tenure_1  tenure_2  \n",
       "listing_id                                                                      \n",
       "5925013098            27.0           276.0           153.0      51.0     378.0  \n",
       "5925007228             NaN           357.0            72.0     225.0     204.0  \n",
       "5925014745            24.0           707.0           539.0     172.0    1074.0  \n",
       "5921274233             NaN           337.0            68.0     268.0     137.0  \n",
       "5925012514            61.0          1124.0            68.0       2.0    1190.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bayarea = run_all(state='CA',filters=[\"region = 'sfbay'\",\"rent>0\"])   # define whatever filters you want here.\n",
    "df_bayarea.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save locally\n",
    "outfile = 'sfbay_listings_04092017.csv'\n",
    "df_bayarea.to_csv(os.path.join(DATA_DIR,outfile), index=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process all data by state\n",
    "Use this to merge all the data by state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for state in fips_state['USPS']:# uncomment when done with testing. \n",
    "    if state != 'DC':   # the DC census data is missing. \n",
    "        print('\\n Working on',state)\n",
    "        df_state = run_all(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_state.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ssh.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Merge listings data with urbansim block-level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first unzip csv file into temp dir\n",
    "os.mkdir('temp') # make temp dir for unzipped files\n",
    "zip_ref = zipfile.ZipFile(os.path.join(BLOCK_DIR,BLOCK_ZFILE), 'r')\n",
    "zip_ref.extractall('temp')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1015)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>res_rents</th>\n",
       "      <th>res_values</th>\n",
       "      <th>square_meters_land</th>\n",
       "      <th>puma10_id</th>\n",
       "      <th>residential_unit_capacity</th>\n",
       "      <th>employment_capacity</th>\n",
       "      <th>rent_impute</th>\n",
       "      <th>...</th>\n",
       "      <th>tracts_prop_persons_8</th>\n",
       "      <th>tracts_prop_persons_9</th>\n",
       "      <th>nodes_du_1500m</th>\n",
       "      <th>nodes_ave_year_built_3000m</th>\n",
       "      <th>tracts_prop_persons_5</th>\n",
       "      <th>tracts_prop_persons_6</th>\n",
       "      <th>tracts_prop_persons_7</th>\n",
       "      <th>tracts_prop_persons_1</th>\n",
       "      <th>tracts_prop_persons_2</th>\n",
       "      <th>tracts_prop_persons_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>060014271001000</td>\n",
       "      <td>-122.233867</td>\n",
       "      <td>37.770270</td>\n",
       "      <td>1475.0</td>\n",
       "      <td>777700.0</td>\n",
       "      <td>0</td>\n",
       "      <td>600105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.241375</td>\n",
       "      <td>1949.245239</td>\n",
       "      <td>0.033789</td>\n",
       "      <td>0.014378</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>0.244428</td>\n",
       "      <td>0.35514</td>\n",
       "      <td>0.180446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>060014271001001</td>\n",
       "      <td>-122.233991</td>\n",
       "      <td>37.769464</td>\n",
       "      <td>1253.0</td>\n",
       "      <td>567900.0</td>\n",
       "      <td>79696</td>\n",
       "      <td>600105</td>\n",
       "      <td>105</td>\n",
       "      <td>367</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.241375</td>\n",
       "      <td>1949.245239</td>\n",
       "      <td>0.033789</td>\n",
       "      <td>0.014378</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>0.244428</td>\n",
       "      <td>0.35514</td>\n",
       "      <td>0.180446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>060014271001002</td>\n",
       "      <td>-122.234301</td>\n",
       "      <td>37.768350</td>\n",
       "      <td>1475.0</td>\n",
       "      <td>777700.0</td>\n",
       "      <td>739</td>\n",
       "      <td>600105</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.241375</td>\n",
       "      <td>1949.245239</td>\n",
       "      <td>0.033789</td>\n",
       "      <td>0.014378</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>0.244428</td>\n",
       "      <td>0.35514</td>\n",
       "      <td>0.180446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>060014271001003</td>\n",
       "      <td>-122.235213</td>\n",
       "      <td>37.768827</td>\n",
       "      <td>1253.0</td>\n",
       "      <td>567900.0</td>\n",
       "      <td>19546</td>\n",
       "      <td>600105</td>\n",
       "      <td>48</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.475714</td>\n",
       "      <td>1949.422974</td>\n",
       "      <td>0.033789</td>\n",
       "      <td>0.014378</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>0.244428</td>\n",
       "      <td>0.35514</td>\n",
       "      <td>0.180446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>060014271001004</td>\n",
       "      <td>-122.236751</td>\n",
       "      <td>37.769734</td>\n",
       "      <td>1253.0</td>\n",
       "      <td>567900.0</td>\n",
       "      <td>14364</td>\n",
       "      <td>600105</td>\n",
       "      <td>35</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.157094</td>\n",
       "      <td>1950.110962</td>\n",
       "      <td>0.033789</td>\n",
       "      <td>0.014378</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>0.244428</td>\n",
       "      <td>0.35514</td>\n",
       "      <td>0.180446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1015 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          block_id           x          y  res_rents  res_values  \\\n",
       "0  060014271001000 -122.233867  37.770270     1475.0    777700.0   \n",
       "1  060014271001001 -122.233991  37.769464     1253.0    567900.0   \n",
       "2  060014271001002 -122.234301  37.768350     1475.0    777700.0   \n",
       "3  060014271001003 -122.235213  37.768827     1253.0    567900.0   \n",
       "4  060014271001004 -122.236751  37.769734     1253.0    567900.0   \n",
       "\n",
       "   square_meters_land  puma10_id  residential_unit_capacity  \\\n",
       "0                   0     600105                          0   \n",
       "1               79696     600105                        105   \n",
       "2                 739     600105                          0   \n",
       "3               19546     600105                         48   \n",
       "4               14364     600105                         35   \n",
       "\n",
       "   employment_capacity  rent_impute          ...            \\\n",
       "0                    0            1          ...             \n",
       "1                  367            0          ...             \n",
       "2                   23            1          ...             \n",
       "3                  108            0          ...             \n",
       "4                  105            0          ...             \n",
       "\n",
       "   tracts_prop_persons_8  tracts_prop_persons_9  nodes_du_1500m  \\\n",
       "0                    0.0                    0.0        7.241375   \n",
       "1                    0.0                    0.0        7.241375   \n",
       "2                    0.0                    0.0        7.241375   \n",
       "3                    0.0                    0.0        7.475714   \n",
       "4                    0.0                    0.0        7.157094   \n",
       "\n",
       "   nodes_ave_year_built_3000m  tracts_prop_persons_5  tracts_prop_persons_6  \\\n",
       "0                 1949.245239               0.033789               0.014378   \n",
       "1                 1949.245239               0.033789               0.014378   \n",
       "2                 1949.245239               0.033789               0.014378   \n",
       "3                 1949.422974               0.033789               0.014378   \n",
       "4                 1950.110962               0.033789               0.014378   \n",
       "\n",
       "   tracts_prop_persons_7  tracts_prop_persons_1  tracts_prop_persons_2  \\\n",
       "0               0.007189               0.244428                0.35514   \n",
       "1               0.007189               0.244428                0.35514   \n",
       "2               0.007189               0.244428                0.35514   \n",
       "3               0.007189               0.244428                0.35514   \n",
       "4               0.007189               0.244428                0.35514   \n",
       "\n",
       "   tracts_prop_persons_3  \n",
       "0               0.180446  \n",
       "1               0.180446  \n",
       "2               0.180446  \n",
       "3               0.180446  \n",
       "4               0.180446  \n",
       "\n",
       "[5 rows x 1015 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temporarily read first 100 lines just to see header names\n",
    "df_temp = pd.read_csv(os.path.join('temp',BLOCK_FILE), nrows=100, dtype={'block_id':str})\n",
    "print(df_temp.shape)\n",
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define the columns we need \n",
    "block_cols = df_temp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['block_id', 'x', 'y', 'res_rents', 'res_values', 'square_meters_land',\n",
       "       'puma10_id', 'residential_unit_capacity', 'employment_capacity',\n",
       "       'rent_impute', 'value_impute', 'place_id', 'taz_id', 'node_id',\n",
       "       'counties_prop_cars_6', 'nodes_low_income_hh_1500m',\n",
       "       'block_groups_median_children', 'tracts_prop_workers_3',\n",
       "       'tracts_prop_workers_2', 'tracts_prop_workers_1',\n",
       "       'tracts_prop_workers_0', 'tracts_prop_workers_5',\n",
       "       'tracts_prop_workers_4', 'block_groups_median_acres',\n",
       "       'counties_prop_year_built_1995', 'prop_sector_id_72',\n",
       "       'prop_sector_id_71', 'pumas_prop_aggr_sector_id_4',\n",
       "       'pumas_prop_aggr_sector_id_3', 'pumas_prop_aggr_sector_id_2',\n",
       "       'pumas_prop_aggr_sector_id_1', 'nodes_post2010_du_5000m',\n",
       "       'pumas_prop_persons_1', 'pumas_prop_persons_2', 'pumas_prop_persons_3',\n",
       "       'pumas_prop_persons_4', 'pumas_prop_persons_5', 'pumas_prop_persons_6',\n",
       "       'pumas_prop_persons_7', 'pumas_prop_persons_8', 'pumas_prop_persons_9',\n",
       "       'tracts_mean_cars', 'tracts_mean_rent', 'nodes_post2000_du_800m',\n",
       "       'total_households', 'pumas_mean_y', 'pumas_mean_x',\n",
       "       'tracts_mean_sector_id', 'nodes_du_400m', 'block_groups_sum_workers',\n",
       "       'pumas_prop_year_built_1930', 'puma10_id_is_0604101',\n",
       "       'puma10_id_is_0604102', 'prop_year_built_2005',\n",
       "       'nodes_ave_workers_1500m', 'counties_prop_children_5',\n",
       "       'res_btype_mode1', 'res_btype_mode2', 'counties_std_persons',\n",
       "       'nodes_jobs_1500m_62', 'prop_children_5', 'block_groups_mean_acres',\n",
       "       'pumas_prop_workers_2', 'block_groups_prop_workers_4',\n",
       "       'block_groups_prop_workers_5', 'puma10_id_is_0608514',\n",
       "       'block_groups_prop_workers_0', 'nodes_own_singlfam_du_3000m',\n",
       "       'block_groups_prop_workers_2', 'block_groups_prop_workers_3',\n",
       "       'nodes_jobs_1500m_agg3', 'pumas_prop_sector_id_42',\n",
       "       'nodes_jobs_1500m_agg1', 'prop_year_built_1995',\n",
       "       'counties_median_race_of_head', 'nodes_jobs_1500m_agg5',\n",
       "       'nodes_jobs_1500m_agg4', 'tracts_prop_children_4',\n",
       "       'block_groups_prop_sector_id_92', 'pumas_prop_year_built_1965',\n",
       "       'counties_median_age_of_head', 'counties_total_residential_units',\n",
       "       'pumas_prop_workers_5', 'block_groups_prop_recent_mover_1',\n",
       "       'block_groups_prop_recent_mover_0',\n",
       "       'counties_density_residential_units', 'counties_prop_sector_id_72',\n",
       "       'prop_workers_0', 'prop_workers_1', 'nodes_jobs_1500m_11',\n",
       "       'prop_workers_3', 'prop_workers_4', 'prop_workers_5', 'tracts_mean_y',\n",
       "       'tracts_mean_x', 'puma10_id_is_0609502', 'puma10_id_is_0609503',\n",
       "       'puma10_id_is_0609501', 'counties_sum_children',\n",
       "       'tracts_prop_year_built_1985'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.columns[:100]\n",
    "#cols_to_drop = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certain columns are definitely not useful. E.g, 'puma10_id_is_0609502', 'puma10_id_is_0609503'\n",
    "'tracts_mean_y', 'tracts_mean_x'\n",
    "\n",
    "TODO: spend more time choosing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-65-c056f67af7df>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-65-c056f67af7df>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    unneeded_cols = [x for x in block_cols if x.startswith('puma10_id_is_')]+\u001b[0m\n\u001b[0m                                                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# make sure to now include unneeded columns like these:\n",
    "unneeded_cols = [x for x in block_cols if x.startswith('puma10_id_is_')]+\n",
    "[x for x in block_cols if (x.endswith('mean_y'))|(x.endswith('mean_x'))]+\n",
    "[x for x in block_cols if (x.endswith('std_y'))|(x.endswith('std_x'))]+\n",
    "[x for x in block_cols if x.startswith('pumas_prop_sector_id')]+\n",
    "[x for x in block_cols if x.startswith('county_id_is_')]+\n",
    "[x for x in block_cols if x.startswith('tracts_prop_sector_id')]+\n",
    "[x for x in block_cols if x.startswith('counties_prop_sector_id')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unneeded_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109228, 45)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block_id</th>\n",
       "      <th>res_rents</th>\n",
       "      <th>res_values</th>\n",
       "      <th>counties_prop_cars_6</th>\n",
       "      <th>nodes_low_income_hh_1500m</th>\n",
       "      <th>block_groups_median_children</th>\n",
       "      <th>tracts_prop_workers_3</th>\n",
       "      <th>tracts_prop_workers_2</th>\n",
       "      <th>tracts_prop_workers_1</th>\n",
       "      <th>tracts_prop_workers_0</th>\n",
       "      <th>...</th>\n",
       "      <th>pumas_mean_x</th>\n",
       "      <th>tracts_mean_sector_id</th>\n",
       "      <th>nodes_du_400m</th>\n",
       "      <th>block_groups_sum_workers</th>\n",
       "      <th>pumas_prop_year_built_1930</th>\n",
       "      <th>puma10_id_is_0604101</th>\n",
       "      <th>puma10_id_is_0604102</th>\n",
       "      <th>prop_year_built_2005</th>\n",
       "      <th>nodes_ave_workers_1500m</th>\n",
       "      <th>counties_prop_children_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>060014271001000</td>\n",
       "      <td>1475.0</td>\n",
       "      <td>777700.0</td>\n",
       "      <td>0.00658</td>\n",
       "      <td>5.991451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047448</td>\n",
       "      <td>0.388929</td>\n",
       "      <td>0.312725</td>\n",
       "      <td>0.23652</td>\n",
       "      <td>...</td>\n",
       "      <td>-122.203215</td>\n",
       "      <td>930.636505</td>\n",
       "      <td>4.264677</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.227894</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.227422</td>\n",
       "      <td>0.002638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>060014271001001</td>\n",
       "      <td>1253.0</td>\n",
       "      <td>567900.0</td>\n",
       "      <td>0.00658</td>\n",
       "      <td>5.991451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047448</td>\n",
       "      <td>0.388929</td>\n",
       "      <td>0.312725</td>\n",
       "      <td>0.23652</td>\n",
       "      <td>...</td>\n",
       "      <td>-122.203215</td>\n",
       "      <td>930.636505</td>\n",
       "      <td>4.264677</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.227894</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.227422</td>\n",
       "      <td>0.002638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>060014271001002</td>\n",
       "      <td>1475.0</td>\n",
       "      <td>777700.0</td>\n",
       "      <td>0.00658</td>\n",
       "      <td>5.991451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047448</td>\n",
       "      <td>0.388929</td>\n",
       "      <td>0.312725</td>\n",
       "      <td>0.23652</td>\n",
       "      <td>...</td>\n",
       "      <td>-122.203215</td>\n",
       "      <td>930.636505</td>\n",
       "      <td>4.264677</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.227894</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.227422</td>\n",
       "      <td>0.002638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>060014271001003</td>\n",
       "      <td>1253.0</td>\n",
       "      <td>567900.0</td>\n",
       "      <td>0.00658</td>\n",
       "      <td>6.231131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047448</td>\n",
       "      <td>0.388929</td>\n",
       "      <td>0.312725</td>\n",
       "      <td>0.23652</td>\n",
       "      <td>...</td>\n",
       "      <td>-122.203215</td>\n",
       "      <td>930.636505</td>\n",
       "      <td>5.081900</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.227894</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>1.231641</td>\n",
       "      <td>0.002638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>060014271001004</td>\n",
       "      <td>1253.0</td>\n",
       "      <td>567900.0</td>\n",
       "      <td>0.00658</td>\n",
       "      <td>6.107350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047448</td>\n",
       "      <td>0.388929</td>\n",
       "      <td>0.312725</td>\n",
       "      <td>0.23652</td>\n",
       "      <td>...</td>\n",
       "      <td>-122.203215</td>\n",
       "      <td>930.636505</td>\n",
       "      <td>4.551438</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.227894</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.223755</td>\n",
       "      <td>0.002638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          block_id  res_rents  res_values  counties_prop_cars_6  \\\n",
       "0  060014271001000     1475.0    777700.0               0.00658   \n",
       "1  060014271001001     1253.0    567900.0               0.00658   \n",
       "2  060014271001002     1475.0    777700.0               0.00658   \n",
       "3  060014271001003     1253.0    567900.0               0.00658   \n",
       "4  060014271001004     1253.0    567900.0               0.00658   \n",
       "\n",
       "   nodes_low_income_hh_1500m  block_groups_median_children  \\\n",
       "0                   5.991451                           0.0   \n",
       "1                   5.991451                           0.0   \n",
       "2                   5.991451                           0.0   \n",
       "3                   6.231131                           0.0   \n",
       "4                   6.107350                           0.0   \n",
       "\n",
       "   tracts_prop_workers_3  tracts_prop_workers_2  tracts_prop_workers_1  \\\n",
       "0               0.047448               0.388929               0.312725   \n",
       "1               0.047448               0.388929               0.312725   \n",
       "2               0.047448               0.388929               0.312725   \n",
       "3               0.047448               0.388929               0.312725   \n",
       "4               0.047448               0.388929               0.312725   \n",
       "\n",
       "   tracts_prop_workers_0            ...             pumas_mean_x  \\\n",
       "0                0.23652            ...              -122.203215   \n",
       "1                0.23652            ...              -122.203215   \n",
       "2                0.23652            ...              -122.203215   \n",
       "3                0.23652            ...              -122.203215   \n",
       "4                0.23652            ...              -122.203215   \n",
       "\n",
       "   tracts_mean_sector_id  nodes_du_400m  block_groups_sum_workers  \\\n",
       "0             930.636505       4.264677                     520.0   \n",
       "1             930.636505       4.264677                     520.0   \n",
       "2             930.636505       4.264677                     520.0   \n",
       "3             930.636505       5.081900                     520.0   \n",
       "4             930.636505       4.551438                     520.0   \n",
       "\n",
       "   pumas_prop_year_built_1930  puma10_id_is_0604101  puma10_id_is_0604102  \\\n",
       "0                    0.227894                     0                     0   \n",
       "1                    0.227894                     0                     0   \n",
       "2                    0.227894                     0                     0   \n",
       "3                    0.227894                     0                     0   \n",
       "4                    0.227894                     0                     0   \n",
       "\n",
       "   prop_year_built_2005  nodes_ave_workers_1500m  counties_prop_children_5  \n",
       "0              0.000000                 1.227422                  0.002638  \n",
       "1              0.200000                 1.227422                  0.002638  \n",
       "2              0.000000                 1.227422                  0.002638  \n",
       "3              0.076923                 1.231641                  0.002638  \n",
       "4              0.125000                 1.223755                  0.002638  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for now, define: \n",
    "# TODO: update these with actual columns to use. \n",
    "cols_to_use = ['block_id', 'res_rents', 'res_values', \n",
    "       'counties_prop_cars_6', 'nodes_low_income_hh_1500m',\n",
    "       'block_groups_median_children', 'tracts_prop_workers_3',\n",
    "       'tracts_prop_workers_2', 'tracts_prop_workers_1',\n",
    "       'tracts_prop_workers_0', 'tracts_prop_workers_5',\n",
    "       'tracts_prop_workers_4', 'block_groups_median_acres',\n",
    "       'counties_prop_year_built_1995', 'prop_sector_id_72',\n",
    "       'prop_sector_id_71', 'pumas_prop_aggr_sector_id_4',\n",
    "       'pumas_prop_aggr_sector_id_3', 'pumas_prop_aggr_sector_id_2',\n",
    "       'pumas_prop_aggr_sector_id_1', 'nodes_post2010_du_5000m',\n",
    "       'pumas_prop_persons_1', 'pumas_prop_persons_2', 'pumas_prop_persons_3',\n",
    "       'pumas_prop_persons_4', 'pumas_prop_persons_5', 'pumas_prop_persons_6',\n",
    "       'pumas_prop_persons_7', 'pumas_prop_persons_8', 'pumas_prop_persons_9',\n",
    "       'tracts_mean_cars', 'tracts_mean_rent', 'nodes_post2000_du_800m',\n",
    "       'total_households', 'pumas_mean_y', 'pumas_mean_x',\n",
    "       'tracts_mean_sector_id', 'nodes_du_400m', 'block_groups_sum_workers',\n",
    "       'pumas_prop_year_built_1930', 'puma10_id_is_0604101',\n",
    "       'puma10_id_is_0604102', 'prop_year_built_2005',\n",
    "       'nodes_ave_workers_1500m', 'counties_prop_children_5']\n",
    "\n",
    "# Read all rows, using only the columns we want\n",
    "df_blocks = pd.read_csv(os.path.join('temp',BLOCK_FILE),dtype={'block_id':str}, usecols = cols_to_use)\n",
    "print(df_blocks.shape)\n",
    "df_blocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    060014271001000\n",
       "1    060014271001001\n",
       "2    060014271001002\n",
       "3    060014271001003\n",
       "4    060014271001004\n",
       "Name: block_id, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_blocks['block_id'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_listings = get_craiglist(filters = [\"region='sfbay'\",\"rent>100\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125560 109228\n",
      "Warning: only 123463 of 125560 rows matched\n"
     ]
    }
   ],
   "source": [
    "# merge listings with vars on block_id\n",
    "df_listings.fips_block.head()\n",
    "\n",
    "print(len(df_listings), len(df_blocks))\n",
    "df_merged = pd.merge(df_listings, df_blocks, left_on='fips_block', right_on='block_id', how='inner')\n",
    "if len(df_merged)<len(df_listings):\n",
    "    print('Warning: only {0} of {1} rows matched'.format(len(df_merged), len(df_listings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->['listing_id', 'date', 'fips_block', 'state', 'region', 'block', 'fips12', 'block_id']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# save to hdf\n",
    "outfile = 'ba_listings.h5'\n",
    "df_merged.to_hdf(os.path.join(DATA_DIR,outfile),'merged')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store data to database\n",
    "\n",
    "We need to create a database table to hold the block-level variables for the rent-predictor app. \n",
    "\n",
    "\n",
    "Steps: \n",
    "\n",
    "1. Create table schema\n",
    "\n",
    "Assume all features are floats unless otherwise specified. \n",
    "\n",
    "(If have a lot that aren't floats, might want to store the variable names and their types as a json so we can refer back to it when we change the variables.)\n",
    "\n",
    "2. Copy data into table\n",
    "\n",
    "Copy data into table. COPY is the fastest way to insert a large amount of data (https://www.postgresql.org/docs/current/static/populate.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# connect to local databse\n",
    "\n",
    "DBNAME = 'rent'\n",
    "HOST = 'localhost'\n",
    "conn_str = \"dbname = {0} host = {1}\".format(DBNAME, HOST)\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(conn_str)\n",
    "    cur = conn.cursor()\n",
    "except:\n",
    "    print (\"Cannot connection. Check settings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first save data as csv. \n",
    "# let's use that temp dir again\n",
    "FULL_PATH = '/Users/lisarayle/Dropbox/craigslist/src/'  # can't use relative path in postgres, I guess\n",
    "csvfile = 'blocks_temp.csv'\n",
    "df_blocks.to_csv(os.path.join('temp',csvfile), index=False)\n",
    "\n",
    "table_name = 'block_vars'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_db_table(col_names,t_name,id_var='block_id'):\n",
    "    \"\"\"Create a new table with schema to hold the block-level data. \n",
    "    Args: \n",
    "        col_names (list): list of names of columns to use. First one can be 'block id'\n",
    "        t_name (str): name of database table\n",
    "        id_var (str): name of id variable (default: 'block_id')\n",
    "    \"\"\"\n",
    "    # drop table if already exists\n",
    "    q = \"DROP TABLE IF EXISTS {}\".format(t_name)\n",
    "    cur.execute(q)\n",
    "    conn.commit()\n",
    "\n",
    "    # build the SQL string\n",
    "    sql_begin = \"CREATE TABLE {0} (id BIGSERIAL PRIMARY KEY, {1} varchar(15) not null, \".format(t_name, id_var)\n",
    "    if col_names[0]==id_var:\n",
    "        sql_middle = \" real,\".join([c for c in col_names[1:]]) # leave off block id if it's there. \n",
    "    else: \n",
    "        sql_middle = \" real,\".join([c for c in col_names])\n",
    "\n",
    "    sql_end = \" real);\"\n",
    "    q = sql_begin+sql_middle+sql_end\n",
    "    \n",
    "    cur.execute(q)\n",
    "    conn.commit()\n",
    "    return \n",
    "\n",
    "def copy_block_data(col_names,t_name,fname):\n",
    "    \"\"\"Copy data from csv file into block variables table. \n",
    "    Args: \n",
    "        col_names (list): list of names of columns to use. First one can be 'block id'\n",
    "        t_name (str): name of database table\n",
    "        fname (str): name of csv file with data\n",
    "    \"\"\"\n",
    "    var_string = ','.join([c for c in col_names])\n",
    "    q=\"COPY {t}({v}) FROM '{f}' DELIMITERS ',' CSV HEADER;\".format(t=t_name,v=var_string, f=os.path.join(FULL_PATH,'temp',fname))\n",
    "    print(q)\n",
    "    cur.execute(q)\n",
    "    conn.commit()\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create_db_table(cols_to_use, table_name)\n",
    "copy_block_data(cols_to_use, table_name, csvfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  '060014271001000',\n",
       "  1475.0,\n",
       "  777700.0,\n",
       "  0.00657999,\n",
       "  5.99145,\n",
       "  0.0,\n",
       "  0.0474479,\n",
       "  0.388929,\n",
       "  0.312725,\n",
       "  0.23652,\n",
       "  0.00215672,\n",
       "  0.0115025,\n",
       "  0.619863,\n",
       "  0.0843466,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0563796,\n",
       "  0.178998,\n",
       "  0.15544,\n",
       "  0.169053,\n",
       "  3.14701,\n",
       "  0.293909,\n",
       "  0.30904,\n",
       "  0.164985,\n",
       "  0.141372,\n",
       "  0.0533942,\n",
       "  0.0226813,\n",
       "  0.00814405,\n",
       "  0.00363029,\n",
       "  0.00181514,\n",
       "  1.94752,\n",
       "  1636.75,\n",
       "  2.94523,\n",
       "  0.0,\n",
       "  37.7364,\n",
       "  -122.203,\n",
       "  930.637,\n",
       "  4.26468,\n",
       "  520.0,\n",
       "  0.227894,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.22742,\n",
       "  0.00263786),\n",
       " (2,\n",
       "  '060014271001001',\n",
       "  1253.0,\n",
       "  567900.0,\n",
       "  0.00657999,\n",
       "  5.99145,\n",
       "  0.0,\n",
       "  0.0474479,\n",
       "  0.388929,\n",
       "  0.312725,\n",
       "  0.23652,\n",
       "  0.00215672,\n",
       "  0.0115025,\n",
       "  0.619863,\n",
       "  0.0843466,\n",
       "  0.168539,\n",
       "  0.00749064,\n",
       "  0.0563796,\n",
       "  0.178998,\n",
       "  0.15544,\n",
       "  0.169053,\n",
       "  3.14701,\n",
       "  0.293909,\n",
       "  0.30904,\n",
       "  0.164985,\n",
       "  0.141372,\n",
       "  0.0533942,\n",
       "  0.0226813,\n",
       "  0.00814405,\n",
       "  0.00363029,\n",
       "  0.00181514,\n",
       "  1.94752,\n",
       "  1636.75,\n",
       "  2.94523,\n",
       "  5.0,\n",
       "  37.7364,\n",
       "  -122.203,\n",
       "  930.637,\n",
       "  4.26468,\n",
       "  520.0,\n",
       "  0.227894,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.2,\n",
       "  1.22742,\n",
       "  0.00263786),\n",
       " (3,\n",
       "  '060014271001002',\n",
       "  1475.0,\n",
       "  777700.0,\n",
       "  0.00657999,\n",
       "  5.99145,\n",
       "  0.0,\n",
       "  0.0474479,\n",
       "  0.388929,\n",
       "  0.312725,\n",
       "  0.23652,\n",
       "  0.00215672,\n",
       "  0.0115025,\n",
       "  0.619863,\n",
       "  0.0843466,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0563796,\n",
       "  0.178998,\n",
       "  0.15544,\n",
       "  0.169053,\n",
       "  3.14701,\n",
       "  0.293909,\n",
       "  0.30904,\n",
       "  0.164985,\n",
       "  0.141372,\n",
       "  0.0533942,\n",
       "  0.0226813,\n",
       "  0.00814405,\n",
       "  0.00363029,\n",
       "  0.00181514,\n",
       "  1.94752,\n",
       "  1636.75,\n",
       "  2.94523,\n",
       "  0.0,\n",
       "  37.7364,\n",
       "  -122.203,\n",
       "  930.637,\n",
       "  4.26468,\n",
       "  520.0,\n",
       "  0.227894,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.22742,\n",
       "  0.00263786),\n",
       " (4,\n",
       "  '060014271001003',\n",
       "  1253.0,\n",
       "  567900.0,\n",
       "  0.00657999,\n",
       "  6.23113,\n",
       "  0.0,\n",
       "  0.0474479,\n",
       "  0.388929,\n",
       "  0.312725,\n",
       "  0.23652,\n",
       "  0.00215672,\n",
       "  0.0115025,\n",
       "  0.619863,\n",
       "  0.0843466,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0563796,\n",
       "  0.178998,\n",
       "  0.15544,\n",
       "  0.169053,\n",
       "  3.25182,\n",
       "  0.293909,\n",
       "  0.30904,\n",
       "  0.164985,\n",
       "  0.141372,\n",
       "  0.0533942,\n",
       "  0.0226813,\n",
       "  0.00814405,\n",
       "  0.00363029,\n",
       "  0.00181514,\n",
       "  1.94752,\n",
       "  1636.75,\n",
       "  3.16243,\n",
       "  10.0,\n",
       "  37.7364,\n",
       "  -122.203,\n",
       "  930.637,\n",
       "  5.0819,\n",
       "  520.0,\n",
       "  0.227894,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0769231,\n",
       "  1.23164,\n",
       "  0.00263786),\n",
       " (5,\n",
       "  '060014271001004',\n",
       "  1253.0,\n",
       "  567900.0,\n",
       "  0.00657999,\n",
       "  6.10735,\n",
       "  0.0,\n",
       "  0.0474479,\n",
       "  0.388929,\n",
       "  0.312725,\n",
       "  0.23652,\n",
       "  0.00215672,\n",
       "  0.0115025,\n",
       "  0.619863,\n",
       "  0.0843466,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0563796,\n",
       "  0.178998,\n",
       "  0.15544,\n",
       "  0.169053,\n",
       "  3.21628,\n",
       "  0.293909,\n",
       "  0.30904,\n",
       "  0.164985,\n",
       "  0.141372,\n",
       "  0.0533942,\n",
       "  0.0226813,\n",
       "  0.00814405,\n",
       "  0.00363029,\n",
       "  0.00181514,\n",
       "  1.94752,\n",
       "  1636.75,\n",
       "  4.29637,\n",
       "  8.0,\n",
       "  37.7364,\n",
       "  -122.203,\n",
       "  930.637,\n",
       "  4.55144,\n",
       "  520.0,\n",
       "  0.227894,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.125,\n",
       "  1.22375,\n",
       "  0.00263786),\n",
       " (6,\n",
       "  '060014271001005',\n",
       "  1475.0,\n",
       "  777700.0,\n",
       "  0.00657999,\n",
       "  6.18346,\n",
       "  0.0,\n",
       "  0.0474479,\n",
       "  0.388929,\n",
       "  0.312725,\n",
       "  0.23652,\n",
       "  0.00215672,\n",
       "  0.0115025,\n",
       "  0.619863,\n",
       "  0.0843466,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0563796,\n",
       "  0.178998,\n",
       "  0.15544,\n",
       "  0.169053,\n",
       "  3.22259,\n",
       "  0.293909,\n",
       "  0.30904,\n",
       "  0.164985,\n",
       "  0.141372,\n",
       "  0.0533942,\n",
       "  0.0226813,\n",
       "  0.00814405,\n",
       "  0.00363029,\n",
       "  0.00181514,\n",
       "  1.94752,\n",
       "  1636.75,\n",
       "  4.05071,\n",
       "  0.0,\n",
       "  37.7364,\n",
       "  -122.203,\n",
       "  930.637,\n",
       "  4.60664,\n",
       "  520.0,\n",
       "  0.227894,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.23416,\n",
       "  0.00263786),\n",
       " (7,\n",
       "  '060014271001006',\n",
       "  1253.0,\n",
       "  567900.0,\n",
       "  0.00657999,\n",
       "  6.18346,\n",
       "  0.0,\n",
       "  0.0474479,\n",
       "  0.388929,\n",
       "  0.312725,\n",
       "  0.23652,\n",
       "  0.00215672,\n",
       "  0.0115025,\n",
       "  0.619863,\n",
       "  0.0843466,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0563796,\n",
       "  0.178998,\n",
       "  0.15544,\n",
       "  0.169053,\n",
       "  3.22259,\n",
       "  0.293909,\n",
       "  0.30904,\n",
       "  0.164985,\n",
       "  0.141372,\n",
       "  0.0533942,\n",
       "  0.0226813,\n",
       "  0.00814405,\n",
       "  0.00363029,\n",
       "  0.00181514,\n",
       "  1.94752,\n",
       "  1636.75,\n",
       "  4.05071,\n",
       "  1.0,\n",
       "  37.7364,\n",
       "  -122.203,\n",
       "  930.637,\n",
       "  4.60664,\n",
       "  520.0,\n",
       "  0.227894,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.23416,\n",
       "  0.00263786),\n",
       " (8,\n",
       "  '060014271001007',\n",
       "  1253.0,\n",
       "  567900.0,\n",
       "  0.00657999,\n",
       "  6.23485,\n",
       "  0.0,\n",
       "  0.0474479,\n",
       "  0.388929,\n",
       "  0.312725,\n",
       "  0.23652,\n",
       "  0.00215672,\n",
       "  0.0115025,\n",
       "  0.619863,\n",
       "  0.0843466,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0563796,\n",
       "  0.178998,\n",
       "  0.15544,\n",
       "  0.169053,\n",
       "  3.22721,\n",
       "  0.293909,\n",
       "  0.30904,\n",
       "  0.164985,\n",
       "  0.141372,\n",
       "  0.0533942,\n",
       "  0.0226813,\n",
       "  0.00814405,\n",
       "  0.00363029,\n",
       "  0.00181514,\n",
       "  1.94752,\n",
       "  1636.75,\n",
       "  3.95711,\n",
       "  9.0,\n",
       "  37.7364,\n",
       "  -122.203,\n",
       "  930.637,\n",
       "  4.70207,\n",
       "  520.0,\n",
       "  0.227894,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.22865,\n",
       "  0.00263786),\n",
       " (9,\n",
       "  '060014271001008',\n",
       "  1475.0,\n",
       "  777700.0,\n",
       "  0.00657999,\n",
       "  5.98591,\n",
       "  0.0,\n",
       "  0.0474479,\n",
       "  0.388929,\n",
       "  0.312725,\n",
       "  0.23652,\n",
       "  0.00215672,\n",
       "  0.0115025,\n",
       "  0.619863,\n",
       "  0.0843466,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0563796,\n",
       "  0.178998,\n",
       "  0.15544,\n",
       "  0.169053,\n",
       "  3.30888,\n",
       "  0.293909,\n",
       "  0.30904,\n",
       "  0.164985,\n",
       "  0.141372,\n",
       "  0.0533942,\n",
       "  0.0226813,\n",
       "  0.00814405,\n",
       "  0.00363029,\n",
       "  0.00181514,\n",
       "  1.94752,\n",
       "  1636.75,\n",
       "  2.97472,\n",
       "  0.0,\n",
       "  37.7364,\n",
       "  -122.203,\n",
       "  930.637,\n",
       "  4.54815,\n",
       "  520.0,\n",
       "  0.227894,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.23107,\n",
       "  0.00263786),\n",
       " (10,\n",
       "  '060014271001009',\n",
       "  1475.0,\n",
       "  777700.0,\n",
       "  0.00657999,\n",
       "  5.90645,\n",
       "  0.0,\n",
       "  0.0474479,\n",
       "  0.388929,\n",
       "  0.312725,\n",
       "  0.23652,\n",
       "  0.00215672,\n",
       "  0.0115025,\n",
       "  0.619863,\n",
       "  0.0843466,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0563796,\n",
       "  0.178998,\n",
       "  0.15544,\n",
       "  0.169053,\n",
       "  3.30013,\n",
       "  0.293909,\n",
       "  0.30904,\n",
       "  0.164985,\n",
       "  0.141372,\n",
       "  0.0533942,\n",
       "  0.0226813,\n",
       "  0.00814405,\n",
       "  0.00363029,\n",
       "  0.00181514,\n",
       "  1.94752,\n",
       "  1636.75,\n",
       "  2.89662,\n",
       "  0.0,\n",
       "  37.7364,\n",
       "  -122.203,\n",
       "  930.637,\n",
       "  3.96652,\n",
       "  520.0,\n",
       "  0.227894,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.23868,\n",
       "  0.00263786)]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test queries\n",
    "\n",
    "q = \"select count(*) from block_vars;\"\n",
    "run_query(q)\n",
    "\n",
    "q = \"select column_name from information_schema.columns where table_name='block_vars';\"\n",
    "run_query(q)\n",
    "\n",
    "q = \"select * from block_vars limit 10;\"\n",
    "run_query(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
